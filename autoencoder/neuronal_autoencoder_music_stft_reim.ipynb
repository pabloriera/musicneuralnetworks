{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN autoencoder on STFT data\n",
    "\n",
    "Taken from https://github.com/pkmital/tensorflow_tutorials/blob/master/python/08_denoising_autoencoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "from  librosa.util import frame\n",
    "from scipy.signal import resample\n",
    "\n",
    "%run ../utils.py\n",
    "%run nnutils.py\n",
    "\n",
    "rc_default()\n",
    "\n",
    "SAVEFIG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"../wavs/\"\n",
    "fname = 'Grisey_partiels.wav'\n",
    "\n",
    "name = fname[:-4]\n",
    "\n",
    "filename = path+fname\n",
    "\n",
    "fs,track = fragment_from_wav(filename,0,140)\n",
    "\n",
    "track = resample(track,int(track.size/2.0))\n",
    "fs = fs/2.0\n",
    "\n",
    "\n",
    "NFFT = 2**11\n",
    "HOP = int(NFFT/4)\n",
    "\n",
    "STFT = librosa.stft(track,n_fft=NFFT, hop_length=HOP,center=True).T\n",
    "mel = librosa.feature.melspectrogram(S=abs(STFT)**2).T\n",
    "\n",
    "X = STFT/float(NFFT)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14,4))\n",
    "librosa.display.specshow(librosa.logamplitude(X.T,ref_power=np.max),hop_length = HOP, sr=fs,y_axis='mel', fmax=8000, x_axis='time')\n",
    "colorbar(label='Intensity (dB)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Dimensions: freq bins, time bins\")\n",
    "X = X[:,:NFFT//2]\n",
    "time_bins,freq_bins = X.shape\n",
    "print(freq_bins,time_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset  (Data class) with real and imaginary parts of spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_ = log10(abs(X)**2)\n",
    "X_ = c_[X.real,X.imag]\n",
    "meanX = X_.mean(0)\n",
    "stdX = X_.std(0)+0.001\n",
    "Xnorm = (X_-meanX)/stdX\n",
    "data = Data( Xnorm )\n",
    "time_bins,freq_bins =data.data.shape\n",
    "print(freq_bins,time_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(14,4))\n",
    "\n",
    "imshow(tanh(X_.T*500),aspect='auto',cmap=cm.seismic,origin='bottom')\n",
    "colorbar();\n",
    "title('Spectrogram with real and imaginary part');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Autoencoder parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_step = 10\n",
    "batch_size = 2000\n",
    "n_epochs = 300\n",
    "learning_rate = 0.0015\n",
    "l2scale = 0.00000000001\n",
    "dimensions= [1024,512,256,128,64,32,16]\n",
    "activation = tf.nn.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nae = NAE(freq_bins,dimensions,activation=activation,bias=True,l2scale=l2scale,learning_rate=learning_rate,stddev=0.1,meaninit=.00)\n",
    "nae.init_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "costlist,costnoreglist = nae.train(data, batch_size, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nae.save(\"checkpoints/NAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(8,4))\n",
    "semilogy(costlist,'g')\n",
    "semilogy(costnoreglist,'b')\n",
    "ylabel('Cost')\n",
    "xlabel('Batchs Steps');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = nae.get_session()\n",
    "variable_dict = nae.get_variables_dict()\n",
    "\n",
    "duration = track.size/fs\n",
    "compare = range(0,time_bins,1)\n",
    "recon = sess.run(variable_dict['Y'], feed_dict={ variable_dict['X']: data.data[compare]})\n",
    "\n",
    "orig = data.data[compare]\n",
    "M =  orig*stdX+meanX \n",
    "M_ = zeros((M.shape[0],M.shape[1]//2+1),dtype=complex64)\n",
    "M_.real[:,:NFFT//2] = M[:,:NFFT//2]\n",
    "M_.imag[:,:NFFT//2] = M[:,NFFT//2:]\n",
    "M = 10*log10(abs(M_))\n",
    "\n",
    "figure(figsize=(14,4))\n",
    "\n",
    "librosa.display.specshow(M.T,hop_length = HOP,sr=fs,y_axis='linear', fmax=8000, x_axis='time',cmap = cm.viridis)\n",
    "\n",
    "title('Input')\n",
    "colorbar(label='Intensity (dB)')\n",
    "if SAVEFIG:plt.savefig('figs/original')\n",
    "\n",
    "M = recon*stdX+meanX\n",
    "M_ = zeros((M.shape[0],M.shape[1]//2+1),dtype=complex64)\n",
    "M_.real[:,:NFFT//2] = M[:,:NFFT//2]\n",
    "M_.imag[:,:NFFT//2] = M[:,NFFT//2:]\n",
    "M = 10*log10(abs(M_))\n",
    "\n",
    "figure(figsize=(14,4))\n",
    "\n",
    "librosa.display.specshow(M.T,hop_length = HOP,sr=fs,y_axis='linear', fmax=8000, x_axis='time',cmap = cm.viridis)\n",
    "\n",
    "title('Autoencoded');\n",
    "colorbar(label='Intensity (dB)');\n",
    "if SAVEFIG: plt.savefig('figs/ae')\n",
    "    \n",
    "figure(figsize=(14,4))\n",
    "Z = sess.run(variable_dict['z'], feed_dict={ variable_dict['X']: data.data[compare]})\n",
    "idx = np.lexsort(Z)\n",
    "librosa.display.specshow(Z.T,hop_length = HOP,sr=fs, x_axis='time')\n",
    "yticks(range(0,Z[0].size,2))\n",
    "ylabel('Neurons')\n",
    "colorbar(label='Activity')\n",
    "if SAVEFIG: plt.savefig('figs/Z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "M = recon*stdX+meanX\n",
    "M_ = zeros((M.shape[0],M.shape[1]//2+1),dtype=complex64)\n",
    "M_.real[:,:NFFT//2] = M[:,:NFFT//2]\n",
    "M_.imag[:,:NFFT//2] = M[:,NFFT//2:]\n",
    "\n",
    "out = librosa.istft(M_.T,hop_length=HOP, win_length=NFFT, center=True)\n",
    "\n",
    "display(Audio(data=out,rate=fs))\n",
    "display(Audio(data=track,rate=fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
